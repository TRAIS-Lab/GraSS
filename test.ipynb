{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*weights_only=False.*\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from _dattri.MLP.load import load_benchmark\n",
    "\n",
    "from _dattri.algorithm.tracin import TracInAttributor\n",
    "# from dattri.algorithm.rps import RPSAttributor\n",
    "from dattri.metrics.metrics import lds\n",
    "from dattri.task import AttributionTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fn = \"relu\"\n",
    "proj_dim = 512\n",
    "\n",
    "projector_kwargs = {\n",
    "    \"proj_dim\": proj_dim,\n",
    "    \"device\": \"cuda\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details, groundtruth = load_benchmark(\n",
    "    model=f\"mlp_{activation_fn}\", dataset=\"mnist\", metric=\"lds\", method=\"Grad-Dot\"\n",
    ")\n",
    "\n",
    "def loss_tracin(params, data_target_pair):\n",
    "    image, label = data_target_pair\n",
    "    image_t = image.unsqueeze(0)\n",
    "    label_t = label.unsqueeze(0)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    yhat = torch.func.functional_call(model_details[\"model\"], params, image_t)\n",
    "    return loss(yhat, label_t.long())\n",
    "\n",
    "task = AttributionTask(\n",
    "    model=model_details[\"model\"].to(\"cuda\"),\n",
    "    loss_func=loss_tracin,\n",
    "    checkpoints=model_details[\"models_full\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    model_details[\"train_dataset\"],\n",
    "    shuffle=False,\n",
    "    batch_size=500,\n",
    "    sampler=model_details[\"train_sampler\"],\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    model_details[\"test_dataset\"],\n",
    "    shuffle=False,\n",
    "    batch_size=500,\n",
    "    sampler=model_details[\"test_sampler\"],\n",
    ")\n",
    "\n",
    "attributor = TracInAttributor(\n",
    "    task=task,\n",
    "    weight_list=torch.ones(1) * 1e-3,\n",
    "    normalized_grad=False,\n",
    "    projector_kwargs=projector_kwargs,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zeros gradient after projection\n",
      "original gradient:\n",
      "tensor([8.0930e-11, 8.0930e-11, 8.0930e-11,  ..., 4.7851e-10, 3.2513e-12,\n",
      "        8.6450e-11], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "All zeros gradient after projection\n",
      "original gradient:\n",
      "tensor([1.4453e-10, 1.4453e-10, 1.4453e-10,  ..., 1.6917e-14, 0.0000e+00,\n",
      "        4.3345e-10], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "All zeros gradient after projection\n",
      "original gradient:\n",
      "tensor([6.0624e-11, 6.0624e-11, 6.0624e-11,  ..., 4.1798e-12, 1.0055e-11,\n",
      "        7.0587e-12], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "Average Sparsity of Original Gradients: 0.4155\n",
      "Average Sparsity of Projected Gradients: 0.0012\n",
      "Average Distance Relative Error (Original vs Projected): 0.0302\n"
     ]
    }
   ],
   "source": [
    "score = attributor.attribute(train_loader, test_loader, verbose=False, sparse_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276310\n",
      "torch.Size([276310, 200])\n",
      "torch.Size([200])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_648055/3963554649.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c = 16 * torch.log(torch.tensor(1 / delta)) * (torch.log(torch.tensor(k / delta)) ** 2) / eps\n",
      "/tmp/ipykernel_648055/3963554649.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  P[j * c_int : (j + 1) * c_int, j] = 1 / torch.sqrt(torch.tensor(c, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-2\n",
    "delta = 1e-1\n",
    "k = 12 * torch.log(torch.tensor(1 / delta)) / eps**2\n",
    "c = 16 * torch.log(torch.tensor(1 / delta)) * (torch.log(torch.tensor(k / delta)) ** 2) / eps\n",
    "\n",
    "# create a Rademaacher vector\n",
    "r = torch.randint(0, 2, size=(10 * 20,), device='cpu', dtype=torch.float32) * 2 - 1\n",
    "\n",
    "k_int = int(k)\n",
    "\n",
    "# create a random hash function from [10 * self.block_size] to [k]\n",
    "h_ = torch.randint(\n",
    "    high=k_int,\n",
    "    size=(10*20,),\n",
    "    device='cpu',\n",
    "    dtype=torch.int64,\n",
    ")\n",
    "\n",
    "print(k_int)\n",
    "# H_ \\in {0, \\pm 1}^{k x (10 * self.block_size)} such that H_{i,j} = r_j if h_(j) = i, 0 otherwise\n",
    "H_ = torch.zeros(\n",
    "    k_int,\n",
    "    10 * 20,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    ")\n",
    "print(H_.shape)\n",
    "print(h_.shape)\n",
    "# for i in range(k_int):\n",
    "#     for j in range(20):\n",
    "#         H_[i, j] = r[j] if h_[j] == i else 0\n",
    "H_[h_, torch.arange(10*20)] = r\n",
    "\n",
    "# P \\in {0, \\pm 1}^{(10 * self.block_size) x self.block_size} such that P_{i,j} = 1 / sqrt(c) if (j-1)c + 1 <= i <= jc, 0 otherwise\n",
    "P = torch.zeros(\n",
    "    10 * 20,\n",
    "    20,\n",
    "    dtype=torch.float32,\n",
    "    device='cpu',\n",
    ")\n",
    "c_int = int(c)\n",
    "for j in range(20):\n",
    "    P[j * c_int : (j + 1) * c_int, j] = 1 / torch.sqrt(torch.tensor(c, dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
