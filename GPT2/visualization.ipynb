{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nodes(file_path):\n",
    "    int_list = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            for item in row:\n",
    "                try:\n",
    "                    int_list.append(int(item))\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: '{item}' could not be converted to an integer and was skipped.\")\n",
    "    return int_list\n",
    "\n",
    "def calculate_one(path):\n",
    "    # score = torch.load(path, map_location=torch.device('cpu'))  # _test_0225_regroup\n",
    "    score = torch.load(path, map_location=torch.device('cpu'))\n",
    "    # score = torch.rand(5000, 500)\n",
    "    print(\"score shape:\", score.shape)\n",
    "\n",
    "    nodes_str = []\n",
    "    for i in range(50):\n",
    "        nodes_str.append(f\"./checkpoints/{i}/train_index.csv\")\n",
    "\n",
    "    full_nodes = [i for i in range(4656)]\n",
    "\n",
    "    node_list = []\n",
    "    for node_str in nodes_str:\n",
    "        numbers = read_nodes(node_str)\n",
    "        index = []\n",
    "        for number in numbers:\n",
    "            index.append(full_nodes.index(number))\n",
    "        node_list.append(index)\n",
    "\n",
    "    loss_list = torch.load(\"./result/gt.pt\", map_location=torch.device('cpu')).detach()\n",
    "\n",
    "    approx_output = []\n",
    "    for i in range(len(nodes_str)):\n",
    "        score_approx_0 = score[node_list[i], :]\n",
    "        sum_0 = torch.sum(score_approx_0, axis=0)\n",
    "        approx_output.append(sum_0)\n",
    "\n",
    "    print(len(loss_list), loss_list[0].shape)\n",
    "    print(len(approx_output), approx_output[0].shape)\n",
    "\n",
    "    res = 0\n",
    "    counter = 0\n",
    "    for i in range(score.shape[1]):\n",
    "        tmp = spearmanr(np.array([approx_output[k][i] for k in range(len(approx_output))]),\n",
    "                        np.array([loss_list[k][i].numpy() for k in range(len(loss_list))])).statistic\n",
    "        if np.isnan(tmp):\n",
    "            print(\"Numerical issue\")\n",
    "            continue\n",
    "        res += tmp\n",
    "        counter += 1\n",
    "\n",
    "    print(counter)\n",
    "\n",
    "    return res/counter, loss_list, approx_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score shape: torch.Size([4, 1])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3155 is out of bounds for dimension 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./result/score.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcalculate_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mcalculate_one\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     35\u001b[0m approx_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(nodes_str)):\n\u001b[0;32m---> 37\u001b[0m     score_approx_0 \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m     sum_0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(score_approx_0, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m     approx_output\u001b[38;5;241m.\u001b[39mappend(sum_0)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3155 is out of bounds for dimension 0 with size 4"
     ]
    }
   ],
   "source": [
    "path = \"./result/score.pt\"\n",
    "print(calculate_one(path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score shape: torch.Size([4, 1])\n",
      "tensor([[0.0619],\n",
      "        [0.0660],\n",
      "        [0.0732],\n",
      "        [0.0473]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.load('./result/score_GIP.pt', map_location=torch.device('cpu'))\n",
    "# score = torch.rand(5000, 500)\n",
    "print(\"score shape:\", score.shape)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score shape: torch.Size([4, 1])\n",
      "tensor([[0.0314],\n",
      "        [0.0454],\n",
      "        [0.0459],\n",
      "        [0.0352]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.load('./result/score.pt', map_location=torch.device('cpu'))\n",
    "# score = torch.rand(5000, 500)\n",
    "print(\"score shape:\", score.shape)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0338    , 0.04152866, 0.04230152, 0.36479268])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.0656, 0.0806, 0.0821, 0.708])\n",
    "\n",
    "x * (0.0338 / 0.0656)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1536]) torch.Size([1, 1536])\n"
     ]
    }
   ],
   "source": [
    "train_gradients = torch.load('train_grad_0.pt', map_location=torch.device('cpu'))\n",
    "test_gradients = torch.load('test_grad_0.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "print(train_gradients.shape, test_gradients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot-product: tensor([[0.0916],\n",
      "        [0.1316],\n",
      "        [0.1209],\n",
      "        [0.1038]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute dot product for dimensions between l_dim to u_dim\n",
    "l_dim = 0\n",
    "u_dim = l_dim + 50257*768\n",
    "\n",
    "print(f\"dot-product: {1e-3 * train_gradients[:, l_dim:u_dim] @ test_gradients[:, l_dim:u_dim].T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 768]) torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "manual_beta_grad = torch.load('manual_beta_grad.pt', map_location=torch.device('cpu'))\n",
    "manual_gamma_grad = torch.load('manual_gamma_grad.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "print(manual_beta_grad.shape, manual_gamma_grad.shape)\n",
    "\n",
    "# stack them\n",
    "manual_grad = torch.cat((manual_beta_grad, manual_gamma_grad), dim=1)\n",
    "# stack train and test gradients\n",
    "grad = torch.cat((train_gradients, test_gradients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1536])\n",
      "torch.Size([5, 1536])\n"
     ]
    }
   ],
   "source": [
    "print(manual_grad.shape)\n",
    "\n",
    "print(grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0056,  0.0055, -0.0154, -0.0061,  0.0099, -0.0260,  0.0063,  0.0004,\n",
      "        -0.0052, -0.0093])\n",
      "tensor([-0.0016, -0.0043, -0.0140, -0.0010,  0.0020, -0.0064, -0.0177, -0.0010,\n",
      "         0.0006, -0.0009])\n",
      "tensor([ 0.0082,  0.0223,  0.0720,  0.0053, -0.0103,  0.0330,  0.0909,  0.0049,\n",
      "        -0.0031,  0.0047], grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.0288, -0.0283,  0.0791,  0.0311, -0.0509,  0.1338, -0.0326, -0.0022,\n",
      "         0.0268,  0.0477], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(manual_grad[0, :10])\n",
    "print(manual_grad[0, 768:778])\n",
    "\n",
    "print(grad[0, :10])\n",
    "print(grad[0, 768:778])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
