{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"import os\n",
				"import torch\n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np\n",
				"import re\n",
				"from scipy.stats import spearmanr\n",
				"import csv\n",
				"\n",
				"import os\n",
				"import sys\n",
				"parent_dir = os.path.abspath('..')\n",
				"sys.path.append(parent_dir)\n",
				"\n",
				"import warnings\n",
				"from GradComp.GPT2LMHeadModel import GCGPT2LMHeadModel\n",
				"from _GradComp.layers.linear import GCLinear, GCEmbedding\n",
				"from _GradComp.layers.layer_norm import GCLayerNorm\n",
				"warnings.filterwarnings(\"ignore\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Setting projector for transformer.h.0.attn.c_attn...\n",
						"Setting projector for transformer.h.0.attn.c_proj...\n",
						"Setting projector for transformer.h.0.mlp.c_fc...\n",
						"Setting projector for transformer.h.0.mlp.c_proj...\n",
						"Setting projector for transformer.h.1.attn.c_attn...\n",
						"Setting projector for transformer.h.1.attn.c_proj...\n",
						"Setting projector for transformer.h.1.mlp.c_fc...\n",
						"Setting projector for transformer.h.1.mlp.c_proj...\n",
						"Setting projector for transformer.h.2.attn.c_attn...\n",
						"Setting projector for transformer.h.2.attn.c_proj...\n",
						"Setting projector for transformer.h.2.mlp.c_fc...\n",
						"Setting projector for transformer.h.2.mlp.c_proj...\n",
						"Setting projector for transformer.h.3.attn.c_attn...\n",
						"Setting projector for transformer.h.3.attn.c_proj...\n",
						"Setting projector for transformer.h.3.mlp.c_fc...\n",
						"Setting projector for transformer.h.3.mlp.c_proj...\n",
						"Setting projector for transformer.h.4.attn.c_attn...\n",
						"Setting projector for transformer.h.4.attn.c_proj...\n",
						"Setting projector for transformer.h.4.mlp.c_fc...\n",
						"Setting projector for transformer.h.4.mlp.c_proj...\n",
						"Setting projector for transformer.h.5.attn.c_attn...\n",
						"Setting projector for transformer.h.5.attn.c_proj...\n",
						"Setting projector for transformer.h.5.mlp.c_fc...\n",
						"Setting projector for transformer.h.5.mlp.c_proj...\n",
						"Setting projector for transformer.h.6.attn.c_attn...\n",
						"Setting projector for transformer.h.6.attn.c_proj...\n",
						"Setting projector for transformer.h.6.mlp.c_fc...\n",
						"Setting projector for transformer.h.6.mlp.c_proj...\n",
						"Setting projector for transformer.h.7.attn.c_attn...\n",
						"Setting projector for transformer.h.7.attn.c_proj...\n",
						"Setting projector for transformer.h.7.mlp.c_fc...\n",
						"Setting projector for transformer.h.7.mlp.c_proj...\n",
						"Setting projector for transformer.h.8.attn.c_attn...\n",
						"Setting projector for transformer.h.8.attn.c_proj...\n",
						"Setting projector for transformer.h.8.mlp.c_fc...\n",
						"Setting projector for transformer.h.8.mlp.c_proj...\n",
						"Setting projector for transformer.h.9.attn.c_attn...\n",
						"Setting projector for transformer.h.9.attn.c_proj...\n",
						"Setting projector for transformer.h.9.mlp.c_fc...\n",
						"Setting projector for transformer.h.9.mlp.c_proj...\n",
						"Setting projector for transformer.h.10.attn.c_attn...\n",
						"Setting projector for transformer.h.10.attn.c_proj...\n",
						"Setting projector for transformer.h.10.mlp.c_fc...\n",
						"Setting projector for transformer.h.10.mlp.c_proj...\n",
						"Setting projector for transformer.h.11.attn.c_attn...\n",
						"Setting projector for transformer.h.11.attn.c_proj...\n",
						"Setting projector for transformer.h.11.mlp.c_fc...\n",
						"Setting projector for transformer.h.11.mlp.c_proj...\n",
						"Setting projector for lm_head...\n"
					]
				}
			],
			"source": [
				"checkpoint = \"./checkpoints/wd=0.0_lr=5e-5/0\"\n",
				"model = GCGPT2LMHeadModel.from_pretrained(checkpoint).cuda(\"cuda:0\")\n",
				"for module_id, (module_name, module) in enumerate(model.named_modules()):\n",
				"    if isinstance(module, GCLinear):\n",
				"        print(f\"Setting projector for {module_name}...\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 35,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"['transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight']\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 2304])\n",
						"torch.Size([2304])\n",
						"torch.Size([768, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768, 3072])\n",
						"torch.Size([3072])\n",
						"torch.Size([3072, 768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([768])\n",
						"torch.Size([50257, 768])\n"
					]
				}
			],
			"source": [
				"print(mask[\"trainable_names\"])\n",
				"for i in range(len(mask[\"binary_mask\"])):\n",
				"    print(mask[\"binary_mask\"][i].shape)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "IF",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.16"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
