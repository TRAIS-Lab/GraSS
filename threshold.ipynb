{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import torch\n",
				"import numpy as np\n",
				"from scipy.stats import spearmanr"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Generate a batch of random sequential data that\n",
				"train_input = torch.randn(100, 500, 64)\n",
				"train_grad_pre_activation = torch.randn(100, 500, 64)\n",
				"\n",
				"test_input = torch.randn(20, 500, 64)\n",
				"test_grad_pre_activation = torch.randn(20, 500, 64)\n",
				"\n",
				"precondition = True"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"# threshold the input and grad_pre_activation\n",
				"threshold = 1e-4\n",
				"\n",
				"train_input_thrd = torch.where(torch.abs(train_input) > threshold, train_input, torch.zeros_like(train_input))\n",
				"train_grad_pre_activation_thrd = torch.where(torch.abs(train_grad_pre_activation) > threshold, train_grad_pre_activation, torch.zeros_like(train_grad_pre_activation))\n",
				"\n",
				"test_input_thrd = torch.where(torch.abs(test_input) > threshold, test_input, torch.zeros_like(test_input))\n",
				"test_grad_pre_activation_thrd = torch.where(torch.abs(test_grad_pre_activation) > threshold, test_grad_pre_activation, torch.zeros_like(test_grad_pre_activation))\n",
				"\n",
				"train_grad_from_thrd = torch.einsum('ijk,ijl->ikl', train_grad_pre_activation_thrd, train_input_thrd).reshape(train_input.shape[0], -1)\n",
				"test_grad_from_thrd = torch.einsum('ijk,ijl->ikl', test_grad_pre_activation_thrd, test_input_thrd).reshape(test_input.shape[0], -1)\n",
				"\n",
				"if precondition:\n",
				"    # Compute empirical covariance of the training data\n",
				"    train_grad_cov_from_thrd = torch.matmul(train_grad_from_thrd.T, train_grad_from_thrd) / train_grad_from_thrd.shape[0]\n",
				"    train_grad_cov_from_thrd_inv = torch.linalg.inv(train_grad_cov_from_thrd)\n",
				"\n",
				"    # Precondition the training data\n",
				"    train_grad_from_thrd_preconditioned = torch.matmul(train_grad_from_thrd, train_grad_cov_from_thrd_inv)\n",
				"\n",
				"    # Compute the inner products between the preconditioned training grad and the original test grad\n",
				"    score_from_thrd = torch.matmul(test_grad_from_thrd, train_grad_from_thrd_preconditioned.T)\n",
				"else:\n",
				"    # Compute the inner products between the original training grad and the original test grad\n",
				"    score_from_thrd = torch.matmul(test_grad_from_thrd, train_grad_from_thrd.T)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"# threshold the gradient\n",
				"threshold = 1e-4\n",
				"\n",
				"train_grad = torch.einsum('ijk,ijl->ikl', train_grad_pre_activation, train_input).reshape(train_input.shape[0], -1)\n",
				"test_grad = torch.einsum('ijk,ijl->ikl', test_grad_pre_activation, test_input).reshape(test_input.shape[0], -1)\n",
				"\n",
				"train_grad_thrd = torch.where(torch.abs(train_grad) > threshold, train_grad, torch.zeros_like(train_grad))\n",
				"test_grad_thrd = torch.where(torch.abs(test_grad) > threshold, test_grad, torch.zeros_like(test_grad))\n",
				"\n",
				"if precondition:\n",
				"    # Compute empirical covariance of the training data\n",
				"    train_grad_cov_thrd = torch.matmul(train_grad_thrd.T, train_grad_thrd) / train_grad_thrd.shape[0]\n",
				"    train_grad_cov_thrd_inv = torch.linalg.inv(train_grad_cov_thrd)\n",
				"\n",
				"    # Precondition the training data\n",
				"    train_grad_thrd_preconditioned = torch.matmul(train_grad_thrd, train_grad_cov_thrd_inv)\n",
				"\n",
				"    # Compute the inner products between the preconditioned training grad and the original test grad\n",
				"    score_thrd = torch.matmul(test_grad_thrd, train_grad_thrd_preconditioned.T)\n",
				"else:\n",
				"    # Compute the inner products between the original training grad and the original test grad\n",
				"    score_thrd = torch.matmul(test_grad_thrd, train_grad_thrd.T)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Correlation between the two scores: 0.01001503759398496\n",
						"Sparsity of the input for thresholding in activation-level: tensor(8.4375e-05)\n",
						"Sparsity of the training grad for thresholding in activation-level: tensor(0.)\n",
						"Sparsity of the training grad for thresholding in gradient-level: tensor(2.4414e-06)\n"
					]
				}
			],
			"source": [
				"def cor(score1, score2):\n",
				"    score1 = score1.detach().cpu()\n",
				"    score2 = score2.detach().cpu()\n",
				"\n",
				"    # Calculate correlations\n",
				"    res = 0\n",
				"    counter = 0\n",
				"    for i in range(score1.shape[1]):\n",
				"        tmp = spearmanr(\n",
				"            np.array([score1[k][i] for k in range(len(score1))]),\n",
				"            np.array([score2[k][i] for k in range(len(score2))])\n",
				"        ).statistic\n",
				"        if not np.isnan(tmp):\n",
				"            res += tmp\n",
				"            counter += 1\n",
				"\n",
				"    return res/counter if counter > 0 else 0\n",
				"\n",
				"print(\"Correlation between the two scores:\", cor(score_from_thrd, score_thrd))\n",
				"\n",
				"# inspect sparsity\n",
				"print(\"Sparsity of the input for thresholding in activation-level:\", torch.sum(train_input_thrd == 0) / train_input_thrd.numel())\n",
				"print(\"Sparsity of the training grad for thresholding in activation-level:\", torch.sum(train_grad_from_thrd == 0) / train_grad_from_thrd.numel())\n",
				"print(\"Sparsity of the training grad for thresholding in gradient-level:\", torch.sum(train_grad_thrd == 0) / train_grad_thrd.numel())"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"tensor([[  5906.5635,   1171.7708,   6660.6597,  ..., -16374.9180,\n",
						"          17444.0156,  12115.5742],\n",
						"        [    40.4005,  20297.1367,  -5061.6709,  ..., -18491.5566,\n",
						"         -14674.6328,  18215.2559],\n",
						"        [ 10681.6045,  10351.2324,  -2357.1326,  ...,   6023.1509,\n",
						"           2103.6333,  -3822.5930],\n",
						"        ...,\n",
						"        [ -9349.6045,  12001.2402,  10609.6855,  ...,   1023.2998,\n",
						"           1928.4727,  20213.6289],\n",
						"        [ -9814.1885,  12448.2676,  28042.7676,  ..., -17129.0312,\n",
						"         -23087.0508,  16753.0430],\n",
						"        [ -6885.1055, -13528.7432,  -7512.0830,  ...,  -2297.2737,\n",
						"          17141.1172,  -4016.5667]])\n"
					]
				}
			],
			"source": [
				"diff = score_from_thrd - score_thrd\n",
				"print(diff)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Condition number of covariance matrix for thresholding in activation-level:  tensor(4.1528e+12)\n",
						"Condition number of covariance matrix for thresholding in gradient-level:  tensor(3.3611e+11)\n",
						"Condition number of covariance matrix inverse for thresholding in activation-level:  tensor(1.4817e+11)\n",
						"Condition number of covariance matrix inverse for thresholding in gradient-level:  tensor(6.7773e+10)\n",
						"Difference of covariance matrices:  tensor(0.2116)\n",
						"Difference of covariance matrices' inverses:  tensor(57798912.)\n",
						"Sparsity of covariance matrix for thresholding in activation-level:  tensor(0.)\n",
						"Sparsity of covariance matrix for thresholding in gradient-level:  tensor(0.)\n"
					]
				}
			],
			"source": [
				"if precondition:\n",
				"    # investigate the condition number for two different covariance matrices\n",
				"    train_grad_cov_from_thrd_cond = torch.linalg.cond(train_grad_cov_from_thrd)\n",
				"    train_grad_cov_thrd_cond = torch.linalg.cond(train_grad_cov_thrd)\n",
				"    print(\"Condition number of covariance matrix for thresholding in activation-level: \", train_grad_cov_from_thrd_cond)\n",
				"    print(\"Condition number of covariance matrix for thresholding in gradient-level: \", train_grad_cov_thrd_cond)\n",
				"\n",
				"    # investigate the condition number for two different covariance matrices\n",
				"    train_grad_cov_from_thrd_inv_cond = torch.linalg.cond(train_grad_cov_from_thrd_inv)\n",
				"    train_grad_cov_thrd_inv_cond = torch.linalg.cond(train_grad_cov_thrd_inv)\n",
				"    print(\"Condition number of covariance matrix inverse for thresholding in activation-level: \", train_grad_cov_from_thrd_inv_cond)\n",
				"    print(\"Condition number of covariance matrix inverse for thresholding in gradient-level: \", train_grad_cov_thrd_inv_cond)\n",
				"\n",
				"    # investigate the difference of two covariance matrices\n",
				"    diff = torch.linalg.norm(train_grad_cov_from_thrd - train_grad_cov_thrd)\n",
				"    print(\"Difference of covariance matrices: \", diff)\n",
				"\n",
				"    # investigate the difference of two covariance matrices' inverses\n",
				"    diff = torch.linalg.norm(train_grad_cov_from_thrd_inv - train_grad_cov_thrd_inv)\n",
				"    print(\"Difference of covariance matrices' inverses: \", diff)\n",
				"\n",
				"    # investigate the sparsity of two covariance matrices\n",
				"    sparsity_from_thrd = torch.sum(train_grad_cov_from_thrd == 0) / train_grad_cov_from_thrd.numel()\n",
				"    sparsity_thrd = torch.sum(train_grad_cov_thrd == 0) / train_grad_cov_thrd.numel()\n",
				"    print(\"Sparsity of covariance matrix for thresholding in activation-level: \", sparsity_from_thrd)\n",
				"    print(\"Sparsity of covariance matrix for thresholding in gradient-level: \", sparsity_thrd)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "IF",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.16"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
